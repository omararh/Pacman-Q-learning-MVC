## Introduction
This project involves implementing various reinforcement learning strategies for the 
Pacman game, including Tabular Q-learning, Approximate Q-learning, neural network-guided 
Q-learning, and Deep Q-learning. Each strategy requires developing and testing algorithms to 
enhance the game's performance across different levels and modes.


### Learning Objectives and Tasks

Each reinforcement learning strategy implemented in this project aims to optimize the decision-making process in the Pacman game, improving the efficiency and intelligence of the agent:

##### Tabular Q-learning: 
Focuses on creating a simple look-up table to store and retrieve values for each state-action pair.  
##### Approximate Q-learning:
Uses weighted features to estimate Q-values, reducing the dimensionality and potentially increasing the learning speed.  
##### Neural Network-guided Q-learning: 
Integrates neural networks to approximate Q-values, providing a powerful way to handle complex scenarios with high state space.  
##### Deep Q-learning: 
Extends neural network capabilities to directly learn the optimal policies over raw game states, aiming for high performance in complex levels.  
